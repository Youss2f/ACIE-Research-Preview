{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21815d47",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a5bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Core imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# ACIE Framework imports\n",
    "from acie import (\n",
    "    ACIE_Core,\n",
    "    ACIETrainer,\n",
    "    ACIERecorder,\n",
    "    ACIEConfig,\n",
    "    CyberLogDataset,\n",
    "    SyntheticDataset\n",
    ")\n",
    "from acie.utils import set_seed, get_device\n",
    "\n",
    "# Set reproducibility\n",
    "set_seed(42)\n",
    "device = get_device(prefer_gpu=True)\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff9713",
   "metadata": {},
   "source": [
    "## 2. Configuration (Governance Layer)\n",
    "\n",
    "The `ACIEConfig` dataclass provides centralized, typed configuration management. This ensures all hyperparameters are validated and documented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de62051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration using the governance layer\n",
    "config = ACIEConfig(\n",
    "    experiment_name=\"research_demo\",\n",
    "    seed=42,\n",
    "    device=\"auto\"\n",
    ")\n",
    "\n",
    "# Configure model architecture\n",
    "config.model.input_dim = 100\n",
    "config.model.causal_nodes = 10\n",
    "config.model.action_space = 5\n",
    "\n",
    "# Configure training hyperparameters\n",
    "config.training.batch_size = 32\n",
    "config.training.epochs = 10  # Reduced for demonstration\n",
    "config.training.learning_rate = 1e-3\n",
    "config.training.lambda_dag = 0.1\n",
    "config.training.lambda_robust = 0.5\n",
    "\n",
    "# Configure data\n",
    "config.data.dataset_type = \"cyber\"\n",
    "config.data.num_samples = 500\n",
    "config.data.train_split = 0.7\n",
    "config.data.val_split = 0.15\n",
    "config.data.test_split = 0.15\n",
    "\n",
    "# Display configuration summary\n",
    "print(config.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a997ae73",
   "metadata": {},
   "source": [
    "## 3. Dataset Loading (Interface Compliance)\n",
    "\n",
    "The `CyberLogDataset` implements the `BaseACIEDataset` interface, ensuring strict interoperability with the training pipeline. This dataset simulates DARPA \"Five Directions\" schema with realistic attack patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CyberLogDataset (implements BaseACIEDataset interface)\n",
    "dataset = CyberLogDataset(\n",
    "    num_samples=config.data.num_samples,\n",
    "    input_dim=config.model.input_dim,\n",
    "    num_classes=config.model.action_space,\n",
    "    seed=config.seed\n",
    ")\n",
    "\n",
    "print(f\"Dataset cardinality: {len(dataset)}\")\n",
    "print(f\"Input dimensionality: {dataset.input_dim}\")\n",
    "print(f\"\\nAttack Patterns:\")\n",
    "for label, pattern in dataset.attack_patterns.items():\n",
    "    print(f\"  {label}: {pattern}\")\n",
    "\n",
    "# Verify interface compliance\n",
    "sample, label = dataset[0]\n",
    "print(f\"\\nSample shape: {sample.shape}\")\n",
    "print(f\"Label type: {type(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964257a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train/val/test\n",
    "train_size = int(config.data.train_split * len(dataset))\n",
    "val_size = int(config.data.val_split * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.training.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.training.batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f01d32",
   "metadata": {},
   "source": [
    "## 4. Model Architecture\n",
    "\n",
    "The `ACIE_Core` model implements a three-layer architecture:\n",
    "\n",
    "1. **Information Filter**: Compressive sensing with entropy gating\n",
    "2. **Causal Discovery**: Differentiable DAG learning (NOTEARS-style)\n",
    "3. **Robust Policy**: Game-theoretic Nash equilibrium selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705c8b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ACIE_Core model\n",
    "model = ACIE_Core(\n",
    "    input_dim=config.model.input_dim,\n",
    "    causal_nodes=config.model.causal_nodes,\n",
    "    action_space=config.model.action_space\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"ACIE_Core Architecture\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"\\nModel components:\")\n",
    "print(f\"  - Sensing matrix: {model.sensing_matrix.shape}\")\n",
    "print(f\"  - Adjacency matrix: {model.adjacency.shape}\")\n",
    "print(f\"  - Policy network: {model.policy_net}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeac399d",
   "metadata": {},
   "source": [
    "## 5. Training (Executive Branch)\n",
    "\n",
    "The `ACIETrainer` handles the optimization loop while delegating logging and persistence to the `ACIERecorder` (Judicial Branch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37d4f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Recorder (Judicial Branch)\n",
    "recorder = ACIERecorder(\n",
    "    experiment_name=config.experiment_name,\n",
    "    save_dir=str(project_root / \"models\"),\n",
    "    log_dir=str(project_root / \"logs\")\n",
    ")\n",
    "\n",
    "# Save configuration\n",
    "recorder.save_config(config.to_dict())\n",
    "\n",
    "# Initialize Trainer (Executive Branch)\n",
    "trainer = ACIETrainer(\n",
    "    model=model,\n",
    "    learning_rate=config.training.learning_rate,\n",
    "    lambda_dag=config.training.lambda_dag,\n",
    "    lambda_robust=config.training.lambda_robust,\n",
    "    device=device,\n",
    "    recorder=recorder\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized successfully\")\n",
    "print(f\"Device: {trainer.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc0ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute training loop\n",
    "history = trainer.fit(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=config.training.epochs,\n",
    "    save_path=str(recorder.save_dir / \"best_model.pth\")\n",
    ")\n",
    "\n",
    "# Save final model and finalize session\n",
    "recorder.save_final_model(model)\n",
    "summary = recorder.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a157244",
   "metadata": {},
   "source": [
    "## 6. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(history[\"train_loss\"], label=\"Train Loss\", color=\"blue\")\n",
    "if history[\"val_loss\"]:\n",
    "    axes[0].plot(history[\"val_loss\"], label=\"Val Loss\", color=\"orange\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Training and Validation Loss\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "if history[\"policy_accuracy\"]:\n",
    "    axes[1].plot(history[\"policy_accuracy\"], label=\"Val Accuracy\", color=\"green\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"Accuracy\")\n",
    "    axes[1].set_title(\"Validation Accuracy\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c475b8",
   "metadata": {},
   "source": [
    "## 7. Adversarial Attack Simulation\n",
    "\n",
    "We simulate adversarial perturbations to evaluate the robustness of the trained model. This demonstrates the game-theoretic defense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7d6018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, data, target, epsilon=0.1):\n",
    "    \"\"\"\n",
    "    Fast Gradient Sign Method (FGSM) attack.\n",
    "    \n",
    "    Args:\n",
    "        model: Target model\n",
    "        data: Input tensor\n",
    "        target: True labels\n",
    "        epsilon: Perturbation magnitude\n",
    "    \n",
    "    Returns:\n",
    "        Perturbed data tensor\n",
    "    \"\"\"\n",
    "    data.requires_grad = True\n",
    "    \n",
    "    output = model(data)\n",
    "    if output == \"NO_THREAT\":\n",
    "        return data\n",
    "    \n",
    "    action_probs, _ = output\n",
    "    loss = torch.nn.CrossEntropyLoss()(action_probs, target)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # FGSM perturbation\n",
    "    perturbation = epsilon * data.grad.sign()\n",
    "    perturbed_data = data + perturbation\n",
    "    \n",
    "    return perturbed_data.detach()\n",
    "\n",
    "\n",
    "# Evaluate on clean vs. adversarial samples\n",
    "model.eval()\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "clean_correct = 0\n",
    "adv_correct = 0\n",
    "total = 0\n",
    "\n",
    "epsilon = 0.1  # Perturbation magnitude\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    \n",
    "    # Clean prediction\n",
    "    with torch.no_grad():\n",
    "        clean_output = model(data)\n",
    "        if clean_output != \"NO_THREAT\":\n",
    "            clean_probs, _ = clean_output\n",
    "            clean_pred = clean_probs.argmax(dim=1)\n",
    "            clean_correct += (clean_pred == target).sum().item()\n",
    "    \n",
    "    # Adversarial prediction\n",
    "    model.train()  # Enable gradients\n",
    "    adv_data = fgsm_attack(model, data.clone(), target, epsilon)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        adv_output = model(adv_data)\n",
    "        if adv_output != \"NO_THREAT\":\n",
    "            adv_probs, _ = adv_output\n",
    "            adv_pred = adv_probs.argmax(dim=1)\n",
    "            adv_correct += (adv_pred == target).sum().item()\n",
    "    \n",
    "    total += target.size(0)\n",
    "\n",
    "clean_acc = clean_correct / total if total > 0 else 0\n",
    "adv_acc = adv_correct / total if total > 0 else 0\n",
    "\n",
    "print(\"Adversarial Robustness Evaluation\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Epsilon: {epsilon}\")\n",
    "print(f\"Clean Accuracy: {clean_acc:.4f}\")\n",
    "print(f\"Adversarial Accuracy: {adv_acc:.4f}\")\n",
    "print(f\"Robustness Gap: {clean_acc - adv_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f0dbb8",
   "metadata": {},
   "source": [
    "## 8. Causal Graph Visualization\n",
    "\n",
    "The learned adjacency matrix represents discovered causal relationships between nodes. We visualize this as a directed graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd4be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract learned adjacency matrix\n",
    "adjacency = model.adjacency.detach().cpu().numpy()\n",
    "\n",
    "# Apply threshold for visualization\n",
    "threshold = 0.1\n",
    "adjacency_thresholded = np.where(np.abs(adjacency) > threshold, adjacency, 0)\n",
    "\n",
    "# Create directed graph\n",
    "G = nx.DiGraph()\n",
    "for i in range(adjacency_thresholded.shape[0]):\n",
    "    G.add_node(i, label=f\"N{i}\")\n",
    "    for j in range(adjacency_thresholded.shape[1]):\n",
    "        if adjacency_thresholded[i, j] != 0:\n",
    "            G.add_edge(i, j, weight=adjacency_thresholded[i, j])\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Heatmap of adjacency matrix\n",
    "im = axes[0].imshow(adjacency, cmap=\"RdBu\", vmin=-1, vmax=1)\n",
    "axes[0].set_title(\"Learned Adjacency Matrix\")\n",
    "axes[0].set_xlabel(\"Target Node\")\n",
    "axes[0].set_ylabel(\"Source Node\")\n",
    "plt.colorbar(im, ax=axes[0], label=\"Edge Weight\")\n",
    "\n",
    "# Graph visualization\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "edge_weights = [G[u][v][\"weight\"] for u, v in G.edges()]\n",
    "edge_colors = [\"red\" if w < 0 else \"blue\" for w in edge_weights]\n",
    "\n",
    "nx.draw(\n",
    "    G, pos, ax=axes[1],\n",
    "    node_color=\"lightblue\",\n",
    "    node_size=500,\n",
    "    with_labels=True,\n",
    "    edge_color=edge_colors,\n",
    "    width=[abs(w) * 2 for w in edge_weights],\n",
    "    arrows=True,\n",
    "    arrowsize=15\n",
    ")\n",
    "axes[1].set_title(f\"Causal Graph (threshold={threshold})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nGraph Statistics:\")\n",
    "print(f\"  Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G.number_of_edges()}\")\n",
    "print(f\"  Is DAG: {nx.is_directed_acyclic_graph(G)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180467f4",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "This notebook demonstrated the full ACIE research pipeline:\n",
    "\n",
    "1. **Configuration**: Centralized hyperparameter management via `ACIEConfig`\n",
    "2. **Data Loading**: Interface-compliant `CyberLogDataset` implementation\n",
    "3. **Training**: Separation of execution (Trainer) and monitoring (Recorder)\n",
    "4. **Adversarial Evaluation**: FGSM attack to assess robustness\n",
    "5. **Causal Visualization**: Learned DAG structure extraction\n",
    "\n",
    "For further experimentation, researchers may:\n",
    "- Modify `config.training` parameters for hyperparameter search\n",
    "- Implement custom datasets inheriting from `BaseACIEDataset`\n",
    "- Extend the `ACIERecorder` for custom logging backends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a132e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"Experiment Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Experiment: {config.experiment_name}\")\n",
    "print(f\"Total Epochs: {config.training.epochs}\")\n",
    "print(f\"Final Train Loss: {history['train_loss'][-1]:.4f}\")\n",
    "if history['val_loss']:\n",
    "    print(f\"Final Val Loss: {history['val_loss'][-1]:.4f}\")\n",
    "if history['policy_accuracy']:\n",
    "    print(f\"Final Val Accuracy: {history['policy_accuracy'][-1]:.4f}\")\n",
    "print(f\"Clean Test Accuracy: {clean_acc:.4f}\")\n",
    "print(f\"Adversarial Test Accuracy: {adv_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
